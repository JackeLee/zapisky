\chapter{Used optimisations in search engines}

In order to write a strong playing program in given game, it is necessary to
enhance chosen algorithm with various extensions. In this chapter we describe
the most used extensions for AlphaBeta or MCTS algorithm.

\section{AlphaBeta}
\subsection{Transposition Table}\label{AlphaBeta:TT}
If we look at the game tree of Arimaa, Chess or Go there is so many repetitions in
nodes of the tree for almost every position on the board. The Transposition table
is used to reduce the number of repetitions in tree.

COMPLETELY REWRITE: If in TT occurs result from previous search that is
shallower than we need, we prefer steps from Principal Variation of given entry
in succeeding search and use also its bounds.

If we find a satisfying result in TT we use its full PV and its score as ours.

\subsection{Iterative Deepening Framework}
Because there is no way how to determine how long the the AlphaBeta search to given
depth will take we need to find some time management tool. This is a method in
which we are iteratively starting new deeper and deeper searches. Thanks to
the exponential growth of the minimax tree with increasing depth we know that
a searching one level more will cost us approximately a lot more than previous
shallower searching.

Iterative deepening used with other optimisation methods such as History
Heuristic or Transposition Table often cause a time save if we compare it to
just searching to a maximal possible depth, because we can sort moves using
information gained from previous shallower searches~\cite{COX}. (TODO rewrite)

\subsection{Aspiration Windows}
% TODO how to mention it?
% \subsection{Quiescent search}
%   Is nice way, how to reduce horizont effect ...
%   % [Related to arimaa: http://arimaa.com/arimaa/forum/cgi/YaBB.cgi?board=devTalk;action=display;num=1122418533] <- TODO: Maybe implement this way
%   % [http://mediocrechess.sourceforge.net/guides/quiescentsearch.html]

\subsection{Move ordering}
The following methods change the order in which branches are selected and then
inspected. It is very important for the AlphaBeta search to have nodes well
ordered. Because earlier we find a pruning child of a node the shorter time
we spend in it.

	\subsubsection{History heuristics}
	The main idea behind this extension is that if some step is good enough
	to cause so many pruning anywhere in the search tree and if it is valid in
	given position it could be also good here.

	It is implemented in way that we create a table with a score for every
	element from combination of players, piece, position and direction. During
	the AlphaBeta search we increase the score for element every time such
	combination causes pruning or finds the best score. It is believed that
	the deeper cut-off happens the more relevant it is and therefore the score
	is incremented by $d^2$ or $2^d$ where $d$ is a actual searched depth.

	During searching are nodes of the minimax tree sorted by score from the
	History Heuristic table in decreasing order~\cite{COX}.

	\subsubsection{Killer moves}
	When a step prunes branches in some position it is very natural to ask if
	the same step could cause pruning in another branch and the same depth of
	the tree. To go even further we take two last steps caused pruning to be
	preferred in the search. As Zhong found out three or more Killer moves would help~\cite{ZHONG}.

	\subsubsection{Null move}


\subsection{Heuristics}
All preceding optimisations do not change result given by the algorithm. They
could only significantly decrease amount of time needed to obtain such result.

The consequent optimisations are rather heuristics, because they try to
give you approximately good result in much shorter time. In this work, we
will not use those optimisations.


- Negascout/PVS
- MTD-f
% TODO XXX: Are really heuristics?


\section{Monte Carlo Tree Search}
In AlphaBeta search we made great effort in sorting nodes of the searched tree
properly. In MCTS we need to use optimisations which helps us to gain better
and more informations from each iteration of algorithm on top of that.
(TODO too complicated, rewrite)

We chose to implement only heuristic Tomáš Kozelek described as
useful~\cite{KOZELEK}.

\subsection{Transposition table}
The motivation is the same as is in the AlphaBeta algorithm
(see~\ref{AlphaBeta:TT}). However in MCTS we are increasingly building game
tree instead of just exploring branches to some depth. A natural use of
Transposition table for MCTS is to share statistics for the same transpositions
in built game tree.

To do so we bind nodes considered the same to one. Bound nodes share their
children nodes, visit count and score statistic. We say that two nodes are the
same if they are in the same depth in minimax tree and if they represent the
same transposition. The game tree became Directed Acyclic Graph.

In implementation during the computation we keep table of all transpositions
and when any node is expanded we bind it to transposition in table if exists.

In Kozelek's work is regarded to be dangerous to bound visit count and score
statistic for children nodes~\cite{KOZELEK}. Nevertheless we believe that if
some step leads us to a position which is proven to be not worth trying in some
branch the same stands for all its transpositions.

\subsection{Progressive bias}
Progressive bias technique is a nice way how to combine offline learned
informations with online learned informations. The more we go through a node
the importance of offline learned information goes down and the importance of
online learned information became superior.

To do so ${H_B \over n_i}$ is added to the UCB formula. Where $H_B$ is
progressive bias coefficient computed by step-evaluation
function~\cite{progressive-strategies}.

In Arimaa such step-evaluation function should appreciate steps with Elephant
moving, killing an opponents piece, around previous steps, which are pushing or
pulling or making goal. Such function should also handicap players own piece
sacrifice steps or inverse steps~\cite{KOZELEK}.

\subsection{History heuristics}
- add to uct formula $+ {hh_i \over n_i}$. Where $hh_i$ is history
heuristics coeficiend as is described in Kozeleks thesis~\cite{KOZELEK}.

Similar approach is All-Moves-As-First Heuristics however it updates statistics only for all steps that were used in this simulation (in each node) (TODO)

\subsection{Best-of-$N$}
In random simulations, we may want to sacrifice true randomness for gaining
more objective results from playouts~\cite{HeavyPlayouts}. $N$ random steps are
generated and a step with the best value given by the same step-evaluation
function as was used in Progressive bias is chosen.

As a consequence, the number of playouts decreases, but the quality of
information learned in playouts improve and therefore the strength of the
program improve also.

\subsection{Children caching}
Kozelek introduced natural method how to decrease an amount of time spent in
node during selection part of the MCTS.

After some number of visits of a node its children caching is switched on. Then
a few best children are chosen and cached and every time the selection part of
the MCTS goes through this node it chooses a descend node from earlier cached
children. After some time it is necessary to discard and fill cache
again~\cite{KOZELEK}.

Using this optimisations should improve the speed of algorithm without negative
impact on quality.

\subsection{Maturity threshold}
TODO: Is another technique how to shorted time used in node selection. We
expand only nodes which had at least $threshold_maternity + depth\_of(node)$
visit count.

This creates 

\subsection{Virtual visits}
In node expansion initialise new node with $v$ virtual visits. This small
change increases the power of the algorithm significantly. Kozelek
experimentally determined the best performance of algorithm for $v \in
[4,5]$~\cite{KOZELEK}.

\section{Independent optimisations}
The following extensions are considered must have in every successful Arimaa
bot and do not depend on used algorithm.

	\subsection{Zobrist keys}
	Motivation ...

	For every element of $Piece\times Player\times Position$ the random 64 bit
	number is generated. ...

	How nodes are stored in Transposition table entries

	\subsection{Bitboards}
	Because Arimaa could be played with standart chess set it is also possible
	to use from world of chess well known board representation called
	Bitboards. One may say that bitboards suits even better for Arimaa than for
	Chess.

\section{Comparison of used optimisations}

\subsection{History heuristic}
In MCTS we prefer moves that were often chosen in going through tree. In
AlphaBeta value of move is increasing when branch using selected step is
pruned. Every time we order branches of the search tree by value given by
history heuristics. This approach should increase amount of pruning.

\subsection{Transposition table}

